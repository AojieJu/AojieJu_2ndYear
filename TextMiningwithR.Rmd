---
title: "Text Mining with R"
author: "Aojie Ju"
date: "11/18/2021"
output: pdf_document
---

```{r}
#Create a character vector.
text<-c("Because I could not stop for Death-",
"He kindly stopped for me-",
"The Carriage held but just Ourselves-",
"and Immortality")

text

#Turn it into a tidy text dataset.
library(dplyr) 
text_df<-tibble(line=1:4,text=text) #tibble builds a data frame here.

text_df

```

Keep in mind that a tibble is not compatible with tidy text analysis, since each row is made up of multiple combined words. So we need to convert this as a "one-token-per-document-per-row."

```{r}
#break the text into individual tokens (tokenization) and transform it to a tidy data structure.
library(tidytext)
text_df %>%
  unnest_tokens(word,text)
#Notice that unnest_tokens leaves out other columns, punctuations, and converts the tokens to lowercase. 
```
Then let's move on and do some additional tidying work. The "janeaustenr" package contains six novels of Jane Austen. The texts in a one-row-per-line format. We'll use "mutate()" to create columns linenumber and chapter.

```{r}
#Construct the dataframe in one-row-per line format.
library(janeaustenr)
library(dplyr)
library(stringr)

original_books<-austen_books()%>%
  group_by(book)%>%
  mutate(linenumber=row_number(),
         chapter=cumsum(str_detect(text,
                              regex("^chapter [\\divxlc]",
                                         ignore_case=TRUE)))) %>%
  ungroup()

original_books

#Restructure it in one-token-per-row format.
library(tidytext)
tidy_books<-original_books%>%
  unnest_tokens(word,text)

tidy_books
```

In many cases, we remove stop words. In package "tidytext," we have a dataset "stop_words" with an "anti_join()."

```{r}
data(stop_words)

tidy_books<-tidy_books%>%
  anti_join(stop_words)
```

How can we count the common words in all of the book? We use "count()" in package "dplyr."

```{r}
tidy_books%>%
  count(word, sort=TRUE)
```
Let's visualize the word counts.

```{r}
library(ggplot2)
tidy_books%>%
  count(word,sort=TRUE)%>%
  filter(n>600)%>%
  mutate(word=reorder(word,n))%>%
  ggplot(aes(n,word))+
  geom_col()+
  labs(y=NULL)
```

Now we turn to another resource by employing "gutenbergr" package. We read four books by H.G. Wells, \textit{The Time Machine}, \textit{The War of the Worlds}, \textit{The Invisible Man}, and \textit{The Island of Doctor Moreau}.

```{r}
library(gutenbergr)

#These are the ID numbers of these books.
hgwells<-gutenberg_download(c(35,36,5230,159),mirror = "http://mirrors.xmission.com/gutenberg/")

tidy_hgwells<-hgwells%>%
  unnest_tokens(word,text)%>%
  anti_join(stop_words)

#Count the most common words in Wells' novels.
tidy_hgwells%>%
  count(word,sort=TRUE)
```
We use Bronte sisters' work to make another example. We get \textit{Jane Eyre}, \textit{Wuthering Heights}, \textit{The Tenant of Wildfell Hall}, \textit{Villette}, and \textit{Agnes Grey}.

```{r}
library(gutenbergr)

bronte<-gutenberg_download(c(1260,768,969,9182,767),mirror = "http://mirrors.xmission.com/gutenberg/")

tidy_bronte<-bronte%>%
  unnest_tokens(word,text)%>%
  anti_join(stop_words)

tidy_bronte%>%
  count(word,sort=TRUE)
```


We calculate the frequency for each word for the works of Jane Austen and H.G. Wells by binding the dataframes together. We use "pivot_wider()" and "pivot_longer()" from package "tidyr" to reshape the dataframe.

```{r}
library(tidyr)

frequency<-bind_rows(mutate(tidy_books,author="Jane Austen"),
                     mutate(tidy_hgwells,author="H.G. Wells"),
                     mutate(tidy_bronte,author="Bronte Sisters"))%>%
  mutate(word=str_extract(word,"[a-z']+"))%>%
  count(author,word)%>%
  group_by(author)%>%
  mutate(proportion=n/sum(n))%>%
  select(-n)%>%
  pivot_wider(names_from=author,values_from=proportion)%>%
  pivot_longer(`Bronte Sisters`:`H.G. Wells`,
               names_to="author",values_to="proportion")

frequency
```
The reason to use "str_extract()" in the above chunk is because UTF-8 encoded texts from Project Gutenberg have some examples that underscores are around some words.

Now plot the comparison of word frequencies of Jane Austen, Bronte Sisters and H.G. Wells.

```{r}
library(scales)

ggplot(frequency, aes(x=proportion,y=`Jane Austen`,
                      color=abs(`Jane Austen`-proportion)))+geom_abline(color="gray40",lty=2)+
  geom_jitter(alpha=0.1,size=2.5,width=0.3,height=0.3)+
  geom_text(aes(label=word),check_overlap=TRUE,vjust=1.5)+
  scale_x_log10(labels=percent_format())+
  scale_y_log10(labels=percent_format())+
  scale_color_gradient(limits=c(0,0.001),
                       low="darkslategray4",high="gray75")+
  facet_wrap(~author,ncol=2)+
  theme(legend.position="none")+
  labs(y="Jane Austen",x=NULL)
```

The graphs show that Bronte Sisters have more similar words with Jane Austen than with H.G. Wells. How similar and different these sets of word frequencies are?

```{r}
cor.test(data=frequency[frequency$author=="Bronte Sisters",],~proportion+`Jane Austen`)
```

